<!DOCTYPE html>
<html lang="es" class="no-js">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zero-Shot Learning - GPAIS | IAFER</title>
    <meta name="description" content="Aprende sobre Zero-Shot Learning: t√©cnicas de aprendizaje sin ejemplos previos mediante transferencia de conocimiento sem√°ntico">
    
    <!-- Fuentes -->
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
    
    <!-- Estilos -->
    <link rel="stylesheet" href="../css/base.css">
    <link rel="stylesheet" href="../css/gpais.css">
</head>
<body id="top">
    
    <!-- Breadcrumb Navigation -->
    <nav class="breadcrumb-nav" aria-label="Navegaci√≥n de ruta">
        <div class="breadcrumb-container">
            <a href="index.html" class="breadcrumb-link">
                <span aria-hidden="true">‚Üê</span>
                <span>GPAIS</span>
            </a>
            <span class="breadcrumb-separator" aria-hidden="true">/</span>
            <span class="breadcrumb-current">Zero-Shot Learning</span>
        </div>
    </nav>

    <!-- Hero Section -->
    <div class="hero-wrapper">
        <div class="hero-particles">
            <div class="particle particle-1"></div>
            <div class="particle particle-2"></div>
            <div class="particle particle-3"></div>
            <div class="particle particle-4"></div>
            <div class="particle particle-5"></div>
        </div>

        <main class="container">
            <section class="hero-card">
                <!-- Badge superior -->
                <div class="hero-badge">
                    <span aria-hidden="true">üéØ</span>
                    <span>Research Focus</span>
                </div>

                <!-- T√≠tulo principal -->
                <h1 class="hero-title">Zero-Shot Learning</h1>
                <p class="hero-subtitle">Aprendizaje sin ejemplos previos mediante transferencia de conocimiento sem√°ntico</p>

                <!-- Botones de acci√≥n -->
                <div class="hero-actions">
                    <a href="#fundamentos" class="btn btn-primary">
                        <span>Explorar contenido</span>
                        <span aria-hidden="true">‚Üí</span>
                    </a>
                    <a href="index.html" class="btn btn-secondary">
                        <span aria-hidden="true">‚Üê</span>
                        <span>Volver a GPAIS</span>
                    </a>
                </div>

                <div class="hero-divider"></div>

                <!-- Introducci√≥n -->
                <section id="fundamentos" class="content-section">
                    <h2 class="section-title">¬øQu√© es Zero-Shot Learning?</h2>
                    <div class="content-text">
                        <p>
                            <strong class="text-highlight">Zero-Shot Learning (ZSL)</strong> es un paradigma de aprendizaje autom√°tico 
                            que permite a los modelos reconocer y clasificar objetos o conceptos que nunca han visto durante el entrenamiento. 
                            A diferencia de los m√©todos tradicionales de aprendizaje supervisado, que requieren numerosos ejemplos etiquetados 
                            de cada clase, ZSL puede generalizar a <strong>clases completamente nuevas</strong> sin ejemplos directos.
                        </p>
                        
                        <p>
                            Este enfoque revolucionario es fundamental para crear sistemas de IA verdaderamente generales, capaces de 
                            adaptarse a nuevos escenarios sin necesidad de reentrenamiento costoso. ZSL logra esto mediante la 
                            <strong>transferencia de conocimiento sem√°ntico</strong>, utilizando descripciones de alto nivel (atributos, 
                            embeddings de texto, o grafos de conocimiento) para relacionar clases conocidas con clases desconocidas.
                        </p>
                    </div>
                </section>
            </section>
        </main>
    </div>

    <!-- Divisor de secci√≥n -->
    <div class="section-divider"></div>

    <!-- Secci√≥n: C√≥mo Funciona -->
    <div class="container">
        <section class="content-section">
            <h2 class="section-title">¬øC√≥mo Funciona?</h2>
            <p class="section-intro">
                El proceso de Zero-Shot Learning se basa en tres componentes clave que trabajan juntos para lograr 
                el reconocimiento de clases no vistas
            </p>
            
            <div class="research-cards">
                <!-- Componente 1 -->
                <article class="research-card">
                    <span class="research-badge">Componente 1</span>
                    <div class="research-icon" aria-hidden="true">üß©</div>
                    <h3 class="research-card-title">Espacio de Caracter√≠sticas Visuales</h3>
                    <p class="research-card-desc">
                        Se extraen caracter√≠sticas visuales de las im√°genes utilizando redes neuronales profundas 
                        pre-entrenadas (como ResNet, ViT, o CLIP). Estas representan los atributos visuales de bajo nivel.
                    </p>
                    <div class="research-card-glow"></div>
                </article>

                <!-- Componente 2 -->
                <article class="research-card">
                    <span class="research-badge">Componente 2</span>
                    <div class="research-icon" aria-hidden="true">üìö</div>
                    <h3 class="research-card-title">Espacio Sem√°ntico</h3>
                    <p class="research-card-desc">
                        Cada clase se describe mediante atributos sem√°nticos, word embeddings (Word2Vec, GloVe) o 
                        embeddings de lenguaje (BERT, GPT). Este espacio codifica el conocimiento humano sobre las clases.
                    </p>
                    <div class="research-card-glow"></div>
                </article>

                <!-- Componente 3 -->
                <article class="research-card">
                    <span class="research-badge">Componente 3</span>
                    <div class="research-icon" aria-hidden="true">üîó</div>
                    <h3 class="research-card-title">Funci√≥n de Compatibilidad</h3>
                    <p class="research-card-desc">
                        Se aprende una funci√≥n que proyecta el espacio visual al espacio sem√°ntico, permitiendo 
                        medir la similitud entre una imagen y las descripciones de clases no vistas durante el test.
                    </p>
                    <div class="research-card-glow"></div>
                </article>
            </div>
        </section>
    </div>

    <!-- Divisor de secci√≥n -->
    <div class="section-divider"></div>

    <!-- Secci√≥n: Tipos de ZSL -->
    <div class="container">
        <section class="content-section">
            <h2 class="section-title">Variantes de Zero-Shot Learning</h2>
            
            <div class="content-grid">
                <!-- Classical ZSL -->
                <article class="info-card">
                    <h3 class="info-card-title">
                        <span class="info-card-icon" aria-hidden="true">üîµ</span>
                        Classical Zero-Shot (CZS)
                    </h3>
                    <p class="info-card-text">
                        Durante el test, el modelo solo encuentra <strong>clases no vistas</strong>. Es el escenario 
                        m√°s desafiante y acad√©mico, pero menos realista en aplicaciones pr√°cticas.
                    </p>
                </article>

                <!-- Generalized ZSL -->
                <article class="info-card">
                    <h3 class="info-card-title">
                        <span class="info-card-icon" aria-hidden="true">üü¢</span>
                        Generalized Zero-Shot (GZSL)
                    </h3>
                    <p class="info-card-text">
                        Durante el test, el modelo debe clasificar entre <strong>clases vistas y no vistas</strong> 
                        simult√°neamente. Es m√°s realista y refleja escenarios del mundo real.
                    </p>
                </article>

                <!-- Transductive ZSL -->
                <article class="info-card">
                    <h3 class="info-card-title">
                        <span class="info-card-icon" aria-hidden="true">üü°</span>
                        Transductive Zero-Shot
                    </h3>
                    <p class="info-card-text">
                        El modelo tiene acceso a las <strong>instancias no etiquetadas</strong> de las clases no vistas 
                        durante el entrenamiento, permitiendo aprovechar su distribuci√≥n.
                    </p>
                </article>
            </div>
        </section>
    </div>

    <!-- Divisor de secci√≥n -->
    <div class="section-divider"></div>

    <!-- Secci√≥n: Aplicaciones -->
    <div class="container">
        <section class="content-section">
            <h2 class="section-title">Aplicaciones Pr√°cticas</h2>
            <div class="content-text">
                <p>
                    El Zero-Shot Learning tiene un impacto significativo en m√∫ltiples dominios donde es imposible 
                    o impracticable obtener ejemplos de entrenamiento para todas las categor√≠as posibles:
                </p>
                
                <ul class="feature-list">
                    <li><strong>Reconocimiento de especies raras:</strong> Clasificaci√≥n de animales en peligro de extinci√≥n sin fotograf√≠as abundantes</li>
                    <li><strong>Diagn√≥stico m√©dico:</strong> Identificaci√≥n de enfermedades raras con pocos casos documentados</li>
                    <li><strong>Reconocimiento de objetos en e-commerce:</strong> Clasificaci√≥n de millones de productos sin etiquetar manualmente cada categor√≠a</li>
                    <li><strong>Detecci√≥n de actividades:</strong> Reconocimiento de acciones humanas complejas o inusuales en video vigilancia</li>
                    <li><strong>B√∫squeda de im√°genes sem√°ntica:</strong> Encontrar im√°genes bas√°ndose en descripciones textuales sin ejemplos previos</li>
                    <li><strong>Rob√≥tica y manipulaci√≥n de objetos:</strong> Robots que reconocen y manipulan objetos nuevos sin reentrenamiento</li>
                </ul>
            </div>
        </section>
    </div>

    <!-- Divisor de secci√≥n -->
    <div class="section-divider"></div>

    <!-- Secci√≥n: Desaf√≠os -->
    <div class="container">
        <section class="content-section">
            <h2 class="section-title">Desaf√≠os Actuales</h2>
            <p class="section-intro">
                A pesar de sus avances, el Zero-Shot Learning enfrenta varios desaf√≠os fundamentales que 
                definen las l√≠neas de investigaci√≥n actuales
            </p>
            
            <div class="challenge-list">
                <div class="challenge-item">
                    <span class="challenge-number">01</span>
                    <h3 class="challenge-title">Domain Shift</h3>
                    <p class="challenge-desc">
                        Discrepancia entre la distribuci√≥n de clases vistas y no vistas, causando que el modelo 
                        tienda a predecir clases vistas incluso para instancias de clases no vistas.
                    </p>
                </div>

                <div class="challenge-item">
                    <span class="challenge-number">02</span>
                    <h3 class="challenge-title">Hubness Problem</h3>
                    <p class="challenge-desc">
                        En espacios de alta dimensionalidad, ciertos puntos ("hubs") se convierten en vecinos 
                        frecuentes de muchos otros, generando clasificaciones sesgadas.
                    </p>
                </div>

                <div class="challenge-item">
                    <span class="challenge-number">03</span>
                    <h3 class="challenge-title">Calidad del Espacio Sem√°ntico</h3>
                    <p class="challenge-desc">
                        La efectividad del ZSL depende cr√≠ticamente de la calidad de las descripciones sem√°nticas, 
                        que pueden ser ruidosas, incompletas o subjetivas.
                    </p>
                </div>

                <div class="challenge-item">
                    <span class="challenge-number">04</span>
                    <h3 class="challenge-title">Bias en GZSL</h3>
                    <p class="challenge-desc">
                        Los modelos tienden a favorecer fuertemente las clases vistas sobre las no vistas, 
                        dificultando el rendimiento equilibrado en escenarios generalizados.
                    </p>
                </div>
            </div>
        </section>
    </div>

    <!-- Divisor de secci√≥n -->
    <div class="section-divider"></div>

    <!-- Secci√≥n: Investigaci√≥n en IAFER -->
    <div class="container">
        <section class="content-section">
            <h2 class="section-title">Nuestra Investigaci√≥n</h2>
            <div class="content-text">
                <p>
                    En el grupo <strong class="text-highlight">GPAIS</strong> del proyecto IAFER, estamos trabajando 
                    en t√©cnicas innovadoras de Zero-Shot Learning que abordan estos desaf√≠os fundamentales:
                </p>
                
                <div class="highlight-box">
                    <h3 class="highlight-title">üöÄ L√≠neas de Investigaci√≥n Activas</h3>
                    <ul class="feature-list">
                        <li><strong>Semantic-Inductive Attribute Selection:</strong> Selecci√≥n de atributos sem√°nticos m√°s discriminativos para mejorar la transferencia de conocimiento</li>
                        <li><strong>Ranking Feature Selection:</strong> T√©cnicas de ranking para identificar las caracter√≠sticas visuales m√°s relevantes en escenarios zero-shot</li>
                        <li><strong>Hybrid ZSL-SSL:</strong> Combinaci√≥n de Zero-Shot Learning con Self-Supervised Learning para aprovechar datos no etiquetados</li>
                        <li><strong>Contrastive ZSL:</strong> Uso de aprendizaje contrastivo para mejorar la separabilidad en el espacio de embeddings</li>
                    </ul>
                </div>
            </div>
        </section>
    </div>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p class="footer-text">
                <strong>Zero-Shot Learning</strong> - GPAIS Research Area
                <span aria-hidden="true">‚Ä¢</span>
                <a href="index.html" class="footer-link">Volver a GPAIS</a>
                <span aria-hidden="true">‚Ä¢</span>
                <a href="../index.html" class="footer-link">IAFER Project 2026</a>
            </p>
        </div>
    </footer>

</body>
</html>
